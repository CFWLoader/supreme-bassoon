{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "e6-1b.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/CFWLoader/supreme-bassoon/blob/master/MachineIntelligence/e6/e6_1b.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "SZgmsd1oqSfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import adam\n",
        "from keras.initializers import random_normal, constant\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 1500, activation = 'relu', input_shape = (784, ), \n",
        "    kernel_initializer = random_normal(mean = 0, stddev = 0.01), bias_initializer = constant(0.1)))\n",
        "model.add(Dense(units = 1500, activation = 'relu', \n",
        "    kernel_initializer = random_normal(mean = 0, stddev = 0.01), bias_initializer = constant(0.1)))\n",
        "model.add(Dense(units = 1500, activation = 'relu',\n",
        "    kernel_initializer = random_normal(mean = 0, stddev = 0.01), bias_initializer = constant(0.1)))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = adam(lr = 0.001, beta_1 = 0.001, beta_2 = 0.999, epsilon = 10e-8),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "    batch_size= 100, epochs= 20\n",
        ")\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['acc', 'loss'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}